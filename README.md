# The Sparks Foundation - Data Science and Business Analytics Internship

## Table of Contents
- [Overview](#overview)
- [Technologies Used](#technologies-used)
- [Tasks](#tasks)
  - [Task 1: Prediction Using Supervised ML](./Task_1.ipynb)
  - [Task 2: Prediction Using Unsupervised ML](./Task_2.ipynb)
  - [Task 3: Exploratory Data Analysis - Retail](./Task_3.ipynb)
  - [Task 4: Exploratory Data Analysis - Terrorism](./Task_4.ipynb)
- [Installation](#installation)
- [How to Run the Notebooks](#how-to-run-the-notebooks)
- [Contributing](#contributing)
- [Contact](#contact)

## Overview
This repository contains the projects completed during my internship at The Sparks Foundation for Data Science and Business Analytics. Each project, stored as a Jupyter Notebook, involves various steps of data analysis including data cleaning, preprocessing, visualization, and model training & evaluation using supervised and unsupervised machine learning models.

## Technologies Used
- **Programming Language:** Python
- **Libraries:** NumPy, Pandas, Matplotlib, Seaborn, scikit-learn
- **Environment:** Jupyter Notebook

## Tasks

### [Task 1]([./Task_1.ipynb]) : Prediction Using Supervised ML

In this task, we use supervised machine learning to predict the score of a student based on the number of hours they studied.

### Problem Statement
What will be the predicted score if a student studies for 9.25 hrs/day?

### Process
- **Data Preprocessing:** Utilize Pandas for data loading and cleaning.
- **Model Training:** Use scikit-learn to train a linear regression model.
- **Prediction:** Predict the score of a student who studies for 9.25 hours a day.
- **Evaluation:** Evaluate the model using metrics like Mean Absolute Error.


### [Task 2](./Task_2.ipynb) : Prediction Using Unsupervised ML

This task involves using unsupervised machine learning to predict the optimum number of clusters from the Iris dataset and visualizing it.

### Problem Statement
From the given ‘Iris’ dataset, predict the optimum number of clusters and represent it visually.

### Process
- **Data Loading:** Load the Iris dataset using Pandas.
- **Exploratory Data Analysis:** Analyze and visualize data trends using Matplotlib and Seaborn.
- **Clustering:** Utilize the K-Means clustering algorithm to identify clusters.
- **Optimal Clusters Determination:** Use the Elbow Method to determine the optimal number of clusters.
- **Visualization:** Visualize the clusters using various plotting techniques.

### [Task 3](./Task_3.ipynb) : Exploratory Data Analysis - Retail
In this task, the objective is to perform an exploratory data analysis on a retail dataset to identify weak areas that could be improved to increase profit.

### Problem Statement
As a business manager, try to find out the weak areas where you can work to make more profit. What all business problems can you derive by exploring the data?

### Process
- **Data Cleaning:** Clean the dataset for any inconsistencies and missing values.
- **Data Analysis:** Utilize Python libraries like Pandas, NumPy for data manipulation and analysis.
- **Data Visualization:** Use Matplotlib and Seaborn to visualize data trends and patterns.
- **Insights & Recommendations:** Identify weak areas and provide actionable insights for increasing profit.

### [Task 4](./Task_4.ipynb) : Exploratory Data Analysis - Terrorism
In this task, the goal is to perform exploratory data analysis on a terrorism dataset to identify hot zones and security issues.

### Problem Statement
As a security/defense analyst, try to find out the hot zone of terrorism. What all security issues and insights can you derive by EDA?

### Process
- **Data Cleaning:** Preprocess the terrorism dataset to clean and organize the data for analysis.
- **Data Analysis:** Use Python libraries to analyze trends and patterns in the data.
- **Data Visualization:** Visualize hot zones and trends in terrorist activities using various plotting techniques.
- **Insights & Recommendations:** Identify security issues and provide actionable insights to address them.

## Installation
- Install the required libraries:
  ``` bash
  pip install numpy pandas matplotlib seaborn scikit-learn jupyter
  ```
- Start Jupyter Notebook:
  ``` bash
  jupyter notebook
  ```
- Open the notebook for Tasks and run the cells to view the analysis and insights.

## How to Run the Notebooks
1. Clone the repository:
```bash
git clone https://github.com/Vedant-Lotia-007/The-Spark-Foundation-Tasks)cd TSF-Data-Science-and-Business-Analytics
```

#### To run the notebook locally:
1. Clone the repository:
```bash
git clone https://github.com/Vedant-Lotia-007/The-Spark-Foundation-Tasks
cd TSF-Data-Science-and-Business-Analytics
```

## Contributing
This repository is primarily for projects completed during the internship, but any suggestions for improvement are welcome. Feel free to open an issue or submit a pull request.

## Contact
For any queries, please feel free to raise an issue on this GitHub repository, or contact the maintainers directly.
